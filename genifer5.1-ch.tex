% Todo:

\documentclass[12pt]{article}
\usepackage[no-math]{fontspec}	% no-math option required for accents package
\usepackage{hyperref}
\usepackage{xeCJK}
%\setCJKmainfont{SimSun}
\setCJKmainfont[BoldFont=SimHei,ItalicFont=KaiTi]{SimSun}
% \setCJKsansfont{SimHei}
% \setCJKmonofont{SimKai}
\setmainfont{Arial}

\usepackage{accents}		% for dots under Chinese for empahsis
\usepackage{cite}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsfonts}
% \usepackage{amsmath}	% for \tag
\usepackage{amssymb}	% for \multimap
% \usepackage{stmaryrd}
\usepackage{color}
%\usepackage[square,numbers]{natbib}
%\nocopyright
%\usepackage{latexsym,amsmath,amssymb,graphicx,hyperref}
%\usepackage{times} % gives you a bit more space if needed
\usepackage{titlesec}		% change color of section headings
\usepackage{verbatim}		% enables to define {comment} blocks
%\usepackage[most]{tcolorbox}		% color box

% Left and right angle brackets
\makeatletter
\newsavebox{\@brx}
\newcommand{\llangle}[1][]{\savebox{\@brx}{\(\m@th{#1\langle}\)}%
  \mathopen{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\newcommand{\rrangle}[1][]{\savebox{\@brx}{\(\m@th{#1\rangle}\)}%
  \mathclose{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\makeatother

% Make dots under Chinese characters for emphasis
\renewcommand{\d}[1]{$\underaccent{\scalebox{0.4}{\textbullet}}{\textrm{#1}}$}
\makeatletter\newcommand{\ds}[1]{\@tfor\next:=#1\do{\d{\next}}}\makeatother

\titleformat{\section}
{\color{blue}\normalfont\Large\bfseries}
{\color{blue}\thesection}{1em}{}
\titleformat{\subsection}
{\color{blue}\normalfont\large\bfseries}
{\color{blue}\thesubsection}{1em}{}

\renewcommand\abstractname{\textcolor{blue}{Abstract}}

\definecolor{LogicColor}{rgb}{0.4,0.1,0.4}  % Magenta
\definecolor{Hilight}{rgb}{0.9,0.9,0.8}  % Magenta
% \definecolor{LogicColor}{rgb}{0,0,0}	% for black-and-white paper

\newcommand{\concept}[1]{\textbf{\textcolor{blue}{#1}}}

\newcommand{\english}[1]{\rmfamily \textit{``#1''}\rmfamily}
\newcommand{\formula}[1]{\textcolor{LogicColor}{#1}}

\newcommand{\hilight}[1]{\begin{tcolorbox}[breakable]#1\end{tcolorbox}}

\newcommand{\tab}{\hspace*{1cm}}

\newcommand*\sigmoid{\vcenter{\hbox{\includegraphics{sigmoid.png}}}}
\newcommand*\sadface{\includegraphics[scale=0.25]{face-sad.png}}

\setlength{\oddsidemargin}{1cm}
\setlength{\evensidemargin}{1cm}
\setlength{\textwidth}{14cm}

\linespread{1.2}

\title{\textcolor{blue}{Genifer 5.1.1 理论笔记}}
\author{YKY (\textit{甄景贤})}
%% \date{30 June 2015}
%% \institute{}

\begin{document}

\begin{comment}
\tab\tab\tab \parbox{9cm}{\textit{.....}}
% \vspace{-0.5cm}
\begin{flushright}
\textemdash\, .... \hspace*{2cm}
\end{flushright}
\end{comment}

% \sffamily

{\let\newpage\relax\maketitle}

\maketitle
\setlength{\parindent}{0em}
\setlength{\parskip}{1.5ex plus0.5ex minus1.2ex}

整个 Genifer 系统包含 RL + RNN 两部分。

\section{RNN}

RNN ($D$) 是一个 feedforward NN，只是它的输出再回溃到输入。

\begin{figure}[H]
\centering
\includegraphics[scale=0.75]{reasoner-model.png}
\end{figure}

它可以执行 3 个运作：

\subsection{Deduction}

Deduction 只需要 forward propagation。  （实际上 deduction 可能没有什么用，重要的是 querying。）

\subsection{Learning}

Learning 是通过 back-prop，我们要求的是从 $K_0$ 开始：
\begin{eqnarray}
K_0 \stackrel{D}{\longrightarrow} .... \; K_\infty \nonumber \\
K_\infty \ge K^*
\end{eqnarray}
但这里需要用到 $\ge$ 关系，下述。

目的是学习 $D$，令误差 $\mathcal{E}$ 最少。

梯度 $\frac{\partial \mathcal{E}}{\partial W}$ 的计算应该是可行的； 这里 $W$ 是 RNN 的 weights。

但怎样计算 $\mathcal{E} = K_\infty - K^*$ ？  有个严重问题是： 我们要知道 $K^*$ 的知识的表达方式，但如果 $D$ 是个 black box，$K^*$ 的 representation 就不是透明的。

Joseph 找到一篇 paper，叫 Memory Networks，来自 Facebook AI research \cite{Weston2015}。 他们也是用 RNN 来学习 Q\& A，但它有一个 component $I$ = input feature map，负责将句子变成 internal feature representation，它需要涉及传统 NLP 的 parsing。 我们可不可以不做这步？ \sadface

问题是如果输出是 words，我们必须比较句子，亦即是 $K$ 的\textbf{序列}。 似乎可以用 convolution 方法： 记 $S := K_0, K_1, K_2, ....$ 为输出的 sequence，$S^* := K^*_0, K^*_1, ..., K^*_m $ 为想要的答案 sequence，则误差可以定义成：
$$ \mathcal{E} := S * S^* $$
其中 $*$ 是 convolution。 （但我不是 100\% 肯定这个用法是否正确。）

\subsection{Querying}

\begin{eqnarray}
K_0 \stackrel{D}{\longrightarrow} .... \; K_\infty \nonumber \\
K_\infty \ge ? \; K^*
\end{eqnarray}

传统逻辑的做法是，找 $K_n$ （$n$ 个推导步骤之后的结果），然后试试 $K_n$ 包不包含 $K^*$。 但通常更有效率是反向地由结论 $K^*$ 开始寻找。

可以看成是这个问题：
\begin{eqnarray}
\mbox{solve}\quad\quad D^n(\mathbf{x}) & > & K^* \nonumber \\
K_0 & \ge & \mathbf{x}
\end{eqnarray}
其中 $\mathbf{x}$ 是变量。 我们要求 $>$ 是大於某个 threshold $\epsilon$。  这是一条 iterative equation，似乎还有希望。

上次说过如果 D 是 monotonous，即 $\forall \mathbf{x} \; D(\mathbf{x}) \ge \mathbf{x}$，可能有帮助。

\subsection{\texorpdfstring{$\ge$}{>} 关系}

$\ge$ 是逻辑中的「generalize」关系，它有两种模式：
\begin{itemize}
\item 人会死 $\ge$ Socrates 会死
\item 人会死 $\ge$ ( 人会死 $\wedge$ 月亮是圆的 ~)
\end{itemize}

在 (topological) vector space 理论里，我们可以定义 vector 之间的 $\mathbf{v}_1 \ge \mathbf{v}_2$，方法是选取任何一个 cone （锥形）$C$：
$$ \mathbf{v}_1 \ge \mathbf{v}_2 \Leftrightarrow (\mathbf{v}_1 - \mathbf{v}_2) \in C $$
例如如果在平面上，$C$ 可以是右上角的 quadrant。

我在考虑： 我们可不可以选取任何一个在 $\mathbf{K}$ 空间中的 cone 来定义 $\ge$，然后让 RNN 自己学习 $\ge$ 的逻辑结构（例如~ 动物 $\ge $ 猫、$A \ge A \wedge B$）？

\begin{comment}
%===========================================================================
\section{RL}

整个 Genifer 系统会是这样的：
\begin{figure}[H]
\centering
\includegraphics[scale=0.75]{genifer-model-0.png}
\end{figure}

设计一个 RL 系统只需定义 4 个元素： \{ 状态 (states)、行动 (actions)、奖励 (rewards)、方案 (policy) \}，其中 policy 是由算法自动计算出来的 states $\rightarrow$ actions 函数。

可以想像 RL 控制一个婴儿慢慢~\ds{调教}她的四肢动作，最后学会走路，这是经典的 RL 应用。

但在 Genifer 中，reasoner 是 Genifer 的一部分，它教导 Genifer 如何思考，但它本身受 RL 控制。

要小心避免 recursive 谬误： 对 RL 来说，reasoner 是一个 external 物体，换句话说，reasoner 虽然是一个导师，但它的内部是\ds{透明的}，这个导师本身可以被 RL 调教。

要小心区分 Genifer 的 actions：
\begin{itemize}
\item 她对外部世界的 actions，例如「举手」、「小便」
\item 她对 reasoner 的 \textit{control actions}
\end{itemize}

上次说过，reasoner 只有3个基本动作： 推导、学习、查询。  如果只能调教这3个 actions，则 RL 的作用不大，所以要将 reasoner 的运作「精细化 (refine)」。

方法是： RL 的 control actions 可以直接改写状态 $K$ 的内容。 例如说：『现在紧急状态，要小便』，那么 Genifer 可能会停下现时的工作，去厕所。

$K$ 的内容基本上是无限制的，所以可以有近乎无限的 actions。 在经典 RL 里，通常用一个 table 记录所有 state-action transitions，但在这情况下我们必须用 function approximation 去近似这个 table，这也没有大碍。 

\section{Remaining problems}

\section{慢吸 (slow absorption)}

第一个问题是，为什么需要慢慢「吸收」句子？
\begin{itemize}
\item 找出与其他句子的关系
\item 逻辑和谐
\item 找出句子下游的逻辑后果
\item 最后，找出最适当的在句子空间中的位置
\end{itemize}

慢吸需要服从的约束是？
\begin{itemize}
\item fast
\item accurate
\item comprehensive (全面)
\end{itemize}
全面的意思是： 在一定复杂性以下可以推导到的结论，就应该推导到（这涉及 $P =? NP$ 问题）。

现在我们似乎只剩下 $G$ 的结构可以改变。 单单改变 G 是否可以达到「更快、更准、更全面」？

%===========================================================================
\end{comment} 

% \section*{Acknowledgments}

\bibliographystyle{plain} % or number or aaai ...
\bibliography{AGI-book}

\end{document}
